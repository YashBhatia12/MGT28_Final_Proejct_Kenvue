# MGT28_Final_Proejct_Kenvue
Kenvue Final Project Plan and Steps

1. Begin by carefully cleaning up the data to ensure its accuracy and reliability. Next, we'll organize the data logically to enhance comprehension. We will identify challenges and utilize tools such as Pandas, Seaborn, and Statsmodels to conduct thorough data analysis to find solutions. Furthermore, we will create graphs to visually represent the data, facilitating the identification of trends and patterns, and then incorporate them into slides. Based on our analysis of the data and sources, we will provide recommendations grounded in facts and evidence.

Our primary goal is to delve deeply into the data provided by Kenvue to uncover trends and correlations among various factors within each Need State that we focused on. Through this process, we aim to identify the challenges Kenvue is facing in terms of the sales of their products. Armed with these insights, we aspire to provide practical recommendations to enhance the company's performance and stimulate growth.

Group Members: Jiayuan Huang, Crystal Lee, Zihan Xu, Yash Bhatia; 
To streamline our workflow, we've divided our team into two groups, each with distinct responsibilities. One-half focuses on the crucial task of data cleaning and organization to facilitate comprehensive data analysis. Additionally, they will adeptly craft visuals using Python and PowerBI to enhance data comprehension. The other half is dedicated to web scraping through APIs, identifying key Need States to target, and constructing regression models. Each team member will take ownership of their respective part in the presentation, preparing slides and providing thorough data analysis and graphical to support our arguments. This division of labor ensures efficiency and accountability, maximizing our collective efforts toward achieving our project goals.

2. For the data cleaning and organization phase of our project, we aim to implement a structured and efficient approach. We will conduct a thorough search for any missing or inconsistent data. In instances of missing data, we plan to employ interpretative methods, such as the use of mean, median, or mean adjusted by standard deviation, to fill these gaps. We plan to conduct examinations for outliers. The outliers will be removed to enhance the precision of our analysis. Our data cleaning strategy is designed to optimize the data for accurate and reliable analysis outcomes.

3. We’ll enhance our analysis through web scraping, utilizing external data sources to gain a more thorough understanding of the factors which influence the operations. This includes collecting information (ie. data) outside of our internal sources (spreadsheets), focusing on citizen’s health, weather conditions, and/or economic indicators. We also want to monitor the activities of Kenvue’s competitors, trying to find out what trends they are following. With these findings, we aim to present our insights and decision-making process.

We’ll focus on using Python, PowerBI, and Tableau for our data analysis; the Python libraries include: NumPy, Pandas, Scikit-learn, Matplotlib, Seaborn, BeautifulSoup for data manipulation and web scraping.

Pseudocode/Algorithm: 
i) Download data and import it; change the formatting
ii) Clean the data (ie. outliers, NaNs)
iii) Visualizations (PowerBI)
iv) Data Analysis (Regression, correlations if needed)
v) Web Scraping 
vi) Graphing trends

